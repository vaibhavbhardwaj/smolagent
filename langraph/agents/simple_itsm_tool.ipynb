{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f4e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "#from langgraph import ToolExecutor, ToolNode\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. Define the Structured Output Model for the Summary\n",
    "class ServerSummary(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured summary of server-related actions and network configurations extracted from text.\n",
    "    \"\"\"\n",
    "    state_server_names: List[str] = Field(\n",
    "        description=\"List of server names mentioned in the text.\"\n",
    "    )\n",
    "    state_server_os: List[str] = Field(\n",
    "        description=\"List of server operating system mentioned in the text.\"\n",
    "    )\n",
    "    state_action: str = Field(\n",
    "        description=\"Overall state action to be performed on servers (e.g., 'deploy', 'shutdown', 'configure').\"\n",
    "    )\n",
    "    state_network_action: List[str] = Field(\n",
    "        description=\"List of network actions mentioned (e.g., 'open port', 'block traffic', 'configure firewall').\"\n",
    "    )\n",
    "    state_network_port: str = Field(\n",
    "        description=\"Specific network port mentioned for network requests, if any. If multiple, pick the most prominent or state 'multiple'.\"\n",
    "    )\n",
    "\n",
    "# 2. Define the LangGraph State\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        file_path: The path to the input text file.\n",
    "        file_content: The extracted content from the file.\n",
    "        summary: The structured summary generated from the file content.\n",
    "        error: Any error message encountered during processing.\n",
    "    \"\"\"\n",
    "    file_path: str\n",
    "    file_content: Annotated[str, \"The content read from the file\"]\n",
    "    summary: Annotated[ServerSummary, \"The structured summarized content\"] # Updated type\n",
    "    error: Annotated[str, \"Any error message encountered\"]\n",
    "\n",
    "\n",
    "# 3. Define the Tools\n",
    "@tool\n",
    "def read_text_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads the content of a text file from the given file path.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        The content of the file as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found at {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "@tool\n",
    "def summarize_text_structured(text: str) -> ServerSummary:\n",
    "    \"\"\"\n",
    "    Summarizes the given input text into a structured ServerSummary object using an LLM.\n",
    "\n",
    "    Args:\n",
    "        text: The text to be summarized.\n",
    "\n",
    "    Returns:\n",
    "        A ServerSummary object containing extracted server and network details.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1) # Lower temperature for more consistent output\n",
    "    \n",
    "    # Use with_structured_output to force the LLM to return a Pydantic object\n",
    "    structured_llm = llm.with_structured_output(ServerSummary)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following text to extract server-related information and network details.\n",
    "    Populate the fields of the ServerSummary model based on the content.\n",
    "    If information for a field is not explicitly available, return an empty list for lists\n",
    "    or an empty string for strings, do NOT hallucinate.\n",
    "\n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response: ServerSummary = structured_llm.invoke(prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        # Return a default empty ServerSummary in case of LLM parsing error\n",
    "        print(f\"Error during structured summarization: {e}\")\n",
    "        return ServerSummary(\n",
    "            state_server_names=[],\n",
    "            state_action=\"\",\n",
    "            state_network_action=[],\n",
    "            state_network_port=\"\"\n",
    "        )\n",
    "\n",
    "# Register the tool (Note: using the new structured tool)\n",
    "#tools = [read_text_file, summarize_text_structured]\n",
    "#tool_executor = ToolExecutor(tools)\n",
    "\n",
    "# 4. Define the Nodes\n",
    "\n",
    "def extract_file_content_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node to extract content from the file.\n",
    "    \"\"\"\n",
    "    file_path = state[\"file_path\"]\n",
    "    print(f\"Attempting to read file: {file_path}\")\n",
    "    content = read_text_file.invoke({\"file_path\": file_path})\n",
    "\n",
    "    if content.startswith(\"Error:\"):\n",
    "        return {\"error\": content, \"file_content\": \"\"}\n",
    "    else:\n",
    "        return {\"file_content\": content, \"error\": \"\"}\n",
    "\n",
    "def summarize_content_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node to summarize the extracted file content into a structured format.\n",
    "    \"\"\"\n",
    "    file_content = state[\"file_content\"]\n",
    "    if not file_content:\n",
    "        print(\"No file content to summarize, skipping summarization.\")\n",
    "        # Return an empty ServerSummary if no content\n",
    "        return {\"summary\": ServerSummary(state_server_names=[], state_action=\"\", state_network_action=[], state_network_port=\"\"), \"error\": \"No content to summarize\"}\n",
    "\n",
    "    print(\"Summarizing file content into structured output...\")\n",
    "    # Call the structured summarization tool\n",
    "    structured_summary = summarize_text_structured.invoke({\"text\": file_content})\n",
    "\n",
    "    # Check if the returned object is indeed a ServerSummary (it should be due to with_structured_output)\n",
    "    if isinstance(structured_summary, ServerSummary):\n",
    "        return {\"summary\": structured_summary, \"error\": \"\"}\n",
    "    else:\n",
    "        # This case should ideally not happen if with_structured_output works as expected\n",
    "        return {\"error\": \"Failed to generate structured summary.\", \n",
    "                \"summary\": ServerSummary(state_server_names=[], state_action=\"\", state_network_action=[], state_network_port=\"\")}\n",
    "\n",
    "def decide_flow_node(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    LangGraph node to decide the next step based on the presence of errors.\n",
    "    \"\"\"\n",
    "    if state.get(\"error\"):\n",
    "        print(f\"Error detected: {state['error']}. Ending graph.\")\n",
    "        return \"end\" # Go to END if there's an error\n",
    "    else:\n",
    "        print(\"No errors, proceeding to summarize content.\")\n",
    "        return \"summarize\" # Proceed to summarization\n",
    "\n",
    "# 5. Build the LangGraph Graph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"extract_content\", extract_file_content_node)\n",
    "workflow.add_node(\"summarize\", summarize_content_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"extract_content\")\n",
    "\n",
    "# Add edges\n",
    "# After extraction, decide whether to summarize or end due to error\n",
    "workflow.add_conditional_edges(\n",
    "    \"extract_content\",\n",
    "    decide_flow_node,\n",
    "    {\n",
    "        \"summarize\": \"summarize\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After summarization, the process ends\n",
    "workflow.add_edge(\"summarize\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70da3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Graph for 'server_log_example.txt' ---\n",
      "Attempting to read file: input.txt\n",
      "No errors, proceeding to summarize content.\n",
      "Summarizing file content into structured output...\n",
      "\n",
      "--- Processing Complete ---\n",
      "\n",
      "Original File Content (partial):\n",
      "build 2 new windows servers sin0m4app2069xd and sin0m4app2070xd and open commnication on port 1858\n",
      "...\n",
      "\n",
      "Structured Summary:\n",
      "  Server Names: ['sin0m4app2069xd', 'sin0m4app2070xd']\n",
      "  Server Operating Sytems: ['Windows']\n",
      "  Overall Action: build\n",
      "  Network Actions: ['open communication']\n",
      "  Network Port: 1858\n"
     ]
    }
   ],
   "source": [
    "# 6. Example Usage\n",
    "\n",
    "# Create a more relevant dummy text file for testing structured output\n",
    "dummy_file_path = \"server_log_example.txt\"\n",
    "\n",
    "with open(dummy_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\"\"\n",
    "[2025-06-14 10:00:00] Initiating deployment to production servers: web-server-01, api-gateway-02.\n",
    "[2025-06-14 10:05:00] Applying firewall rules. Opening port 80 for HTTP traffic.\n",
    "[2025-06-14 10:10:00] Configuration complete for both servers. Monitoring status.\n",
    "[2025-06-14 10:15:00] Traffic redirection successful. Testing connectivity on port 443.\n",
    "[2025-06-14 11:00:00] Scheduled maintenance: Shutting down db-server-03 for disk upgrade.\n",
    "\"\"\")\n",
    "\n",
    "# Run the graph\n",
    "print(f\"\\n--- Running Graph for '{dummy_file_path}' ---\")\n",
    "initial_state = {\"file_path\": \"input.txt\", \"file_content\": \"\", \"summary\": ServerSummary(state_server_names=[], state_server_os=[],state_action=\"\", state_network_action=[], state_network_port=\"\"), \"error\": \"\"}\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "if final_state.get(\"error\"):\n",
    "    print(\"\\n--- Processing Failed ---\")\n",
    "    print(f\"Error: {final_state['error']}\")\n",
    "else:\n",
    "    print(\"\\n--- Processing Complete ---\")\n",
    "    print(\"\\nOriginal File Content (partial):\")\n",
    "    print(final_state['file_content'][:300] + \"...\") # Print first 300 chars\n",
    "    \n",
    "    print(\"\\nStructured Summary:\")\n",
    "    summary_obj = final_state['summary']\n",
    "    if isinstance(summary_obj, ServerSummary):\n",
    "        print(f\"  Server Names: {summary_obj.state_server_names}\")\n",
    "        print(f\"  Server Operating Sytems: {summary_obj.state_server_os}\")\n",
    "        print(f\"  Overall Action: {summary_obj.state_action}\")\n",
    "        print(f\"  Network Actions: {summary_obj.state_network_action}\")\n",
    "        print(f\"  Network Port: {summary_obj.state_network_port}\")\n",
    "    else:\n",
    "        print(\"  Error: Summary is not in the expected structured format.\")\n",
    "        print(f\"  Raw Summary: {summary_obj}\")\n",
    "\n",
    "\n",
    "# Test with a non-existent file\n",
    "# non_existent_file_path = \"non_existent_file.txt\"\n",
    "# print(f\"\\n--- Running Graph for '{non_existent_file_path}' (expecting error) ---\")\n",
    "# initial_state_error = {\"file_path\": non_existent_file_path, \"file_content\": \"\", \"summary\": ServerSummary(state_server_names=[], state_action=\"\", state_network_action=[], state_network_port=\"\"), \"error\": \"\"}\n",
    "# final_state_error = app.invoke(initial_state_error)\n",
    "\n",
    "# if final_state_error.get(\"error\"):\n",
    "#     print(\"\\n--- Processing Failed (as expected) ---\")\n",
    "#     print(f\"Error: {final_state_error['error']}\")\n",
    "# else:\n",
    "#     print(\"\\n--- Unexpected Success (should have failed) ---\")\n",
    "#     print(f\"Summary: {final_state_error['summary']}\")\n",
    "\n",
    "# Clean up the dummy file\n",
    "#os.remove(dummy_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b9c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
