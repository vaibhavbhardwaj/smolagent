{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "faf9c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence,List,Union\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage,AIMessage,AnyMessage\n",
    "from operator import add as add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b65e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0d556",
   "metadata": {},
   "source": [
    " Smart Research and Summarization Agent with Feedback Loop:\n",
    "\n",
    "Concept: This agent would go beyond a simple RAG (Retrieval Augmented Generation) system. It would perform web research on a given topic, summarize the findings, and then have a \"reflection\" or \"critique\" agent review the summary. If the critique agent finds the summary lacking (e.g., missing key details, not answering the user's specific sub-questions), it would trigger further research and refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ea6a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "621fc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the LangGraph State\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        search: input search query by the user.\n",
    "        summary: summary generated by the research agent.\n",
    "        review: review performed by the review agent.\n",
    "        error: Any error message encountered during processing.\n",
    "    \"\"\"\n",
    "    input_str: str\n",
    "    #web_search: Annotated[str, \"results from web search\"]\n",
    "    summary: str\n",
    "    #messages: Annotated[list[AnyMessage], add_messages]\n",
    "    messages : List[Union[HumanMessage,AIMessage]]\n",
    "    #review: Annotated[str, \"The structured summarized content\"] # Updated type\n",
    "    #error: Annotated[str, \"Any error message encountered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0e8a38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define nodes\n",
    "\n",
    "def search_summary_text(state:GraphState)->GraphState:\n",
    "    \"\"\"\n",
    "    Takes the input from user and performs web search\n",
    "\n",
    "    Args:\n",
    "        state: The state of the Graph containg search string\n",
    "    Returns:\n",
    "        Update state of the graph with search results.\n",
    "    \"\"\"\n",
    "    print(\"state\",state)\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\")\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    tools=[search]\n",
    "    llm_with_tool = llm.bind_tools(tools)\n",
    "    input_str = state[\"input_str\"]\n",
    "    # Prompt Template\n",
    "    prompt_template = f\"\"\"Search web for the query and generate concise and accurate summary in less than 50 words.\n",
    "    Query: {input_str}\n",
    "    \"\"\"\n",
    "    response = llm_with_tool.invoke([SystemMessage(content=prompt_template)] +\n",
    "                          [HumanMessage(content=\"Provide the response.\")])\n",
    "    # Return a new state with the summary added\n",
    "    #state = dict(state)\n",
    "    state['input_str']= input_str\n",
    "    state[\"summary\"] = response.content\n",
    "    state[\"messages\"] = response\n",
    "    return state\n",
    "    \n",
    "def analyse_summary(state:GraphState)->GraphState:\n",
    "    \"\"\"\n",
    "    Analyse the summary generated by the agent and provide review\n",
    "\n",
    "    Args:\n",
    "        state: The state of the Graph containg search string\n",
    "    Returns:\n",
    "        Update state of the graph with search results.\n",
    "    \"\"\"\n",
    "    print(\"analyzing summary\",state)\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\")\n",
    "    input_summary = state[\"summary\"]\n",
    "    input_str = state[\"input_str\"]\n",
    "    # Prompt Template\n",
    "    prompt_template = f\"\"\"Analyse the input string and the summary and confirm if the summary is accurate and relevant.\n",
    "    If the summary is accurate, return \"Summary is accurate\". If not, provide a detailed review of the summary.\n",
    "    Input String: {input_str}\n",
    "    Summary: {input_summary}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([SystemMessage(content=prompt_template)] +\n",
    "                          [HumanMessage(content=\"Provide the response.\")])\n",
    "    # Return a new state with the review added\n",
    "    print(\"response\",response.content)\n",
    "    #new_state = dict(state)\n",
    "    state[\"review\"] = response.content\n",
    "    #state['input_str']= input_str\n",
    "    #state[\"summary\"] = input_summary\n",
    "    #print(\"new state\",state)\n",
    "    state[\"messages\"] = [response]\n",
    "    return state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a4fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6eb6f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "work = StateGraph(GraphState)\n",
    "work.add_node(\"search_summary\", search_summary_text)\n",
    "work.add_node(\"analyse_summary\", analyse_summary)\n",
    "work.set_entry_point(\"search_summary\")\n",
    "work.add_edge(\"search_summary\",\"analyse_summary\")\n",
    "work.add_edge(\"analyse_summary\", END)\n",
    "app = work.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6d891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d2304c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state {'input_str': 'What is langgraph?', 'summary': '', 'messages': []}\n",
      "analyzing summary {'input_str': 'What is langgraph?', 'summary': 'Langgraph is a graph-based representation of programming languages, allowing for efficient analysis and manipulation of source code.', 'messages': AIMessage(content='Langgraph is a graph-based representation of programming languages, allowing for efficient analysis and manipulation of source code.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 941, 'total_tokens': 963, 'completion_time': 0.135937402, 'prompt_time': 0.031529108, 'queue_time': 0.206325984, 'total_time': 0.16746651}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None}, id='run--30e93d49-0091-4118-b008-1a4065da54f2-0', usage_metadata={'input_tokens': 941, 'output_tokens': 22, 'total_tokens': 963})}\n",
      "response Summary is accurate.\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"input_str\": \"What is langgraph?\",\n",
    "    \"summary\": \"\",\n",
    "    \"review\": \"\",  # Initialize review if needed,\n",
    "    \"messages\": []  # Initialize messages as an empty list\n",
    "    \n",
    "}\n",
    "response = app.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "89aec43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_str': 'What is langgraph?',\n",
       " 'summary': 'Langgraph is a graph-based representation of programming languages, allowing for efficient analysis and manipulation of source code.',\n",
       " 'messages': [AIMessage(content='Summary is accurate.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 95, 'total_tokens': 100, 'completion_time': 0.048424157, 'prompt_time': 0.002719214, 'queue_time': 0.218770152, 'total_time': 0.051143371}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None}, id='run--4297a950-620a-4380-af64-b8337ceb67f3-0', usage_metadata={'input_tokens': 95, 'output_tokens': 5, 'total_tokens': 100})]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a038520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647152a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3a8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
